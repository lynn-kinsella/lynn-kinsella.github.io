{
    "projectsMin": [
        {
            "name": "Mobile Mind",
            "desc": "An EEG and eye-tracking controlled wheelchair.",
            "id": 0
        },
        {
            "name": "EV Visualizer",
            "desc": "A tool for visualizing the space of Pokemon EVs.",
            "id": 1
        },
        {
            "name": "Crazy 8s",
            "desc": "A React app for a classic card game.",
            "id": 2
        },
        {
            "name": "Match\u00ADmak\u00ADing Bot",
            "desc": "A discord bot to make fair games among friends.",
            "id": 3
        },
        {
            "name": "IV Calc\u00ADul\u00ADator",
            "desc": "An android app that determines a Pokemon's hidden stats from a photo.",
            "id": 4
        }
    ],
    "projectsMax": [
        {
            "link": "",
            "subheading": "A Hands Free EEG and Eye Tracking Controlled Electric Wheelchair",
            "bodyParagraphs": [
                "Mobile Mind is a hands free electric wheelchair, controlled using input from an EEG headband and eye tracking camera. The wheelchair responds to the user's intent to accelerate and decelerate based on their brainwaves, and turns to the left and right based on where they are looking. This project was completed over the course of 8 months in a team of 3 other students as our final year capstone project at McMaster University.",
                "In the early phase of the project, I worked with Ridvan Song to research and experiment with ways to transmit and process the EEG signals that our hardware acquired. Once we had established that we could send the signals over the internet via an Open Sound Control (OSC) server, I developed our first data acquisition experiments, where a user would be prompted to focus on the thought of either “STOP” or “GO”, and the signals from the EEG during that period would be saved and labelled for inspection, and later for training data. I then experimented with different data visualization techniques to evaluate the quality of our data, considering the possibility of using a spectrogram or discrete wavelet transform as both techniques account for changes in amplitude and frequency over time.",
                "In the later stages of the project, I wrote the back-end framework that accepted data from the input devices, processed that data in regular intervals, and sent output signals to the wheelchair motors. The EEG signals were transmitted via OSC like in the earlier experiments, and the video from the eye tracking camera was streamed over a TCPsocket. After being received, the signals were placed into shared queues so that they could be processed in the main process loop on the next iteration.",
                "The main loop was a state machine that took the raw signals, made predictions based on them (using a tensorflow model to predict the user's thought based on a buffer of samples or openCV to predict the direction the user is looking based on the placement of their irises). The results of these predictions were used to control internal speed and angle. Based on the predictions, in each iteration of the main loop the internal speed and angle were updated to step towards a target value. At the end of each loop, the internal speed and angle values were mapped to speeds for the left and right motors.",
                "The biggest challenge in my role with Mobile Mind was integrating all the subsystems together. I accomplished this by breaking each subsystem into its own process, both for modularity and performance. The main loop could request the most up to date values from each process via shared queues, and update its internal state with new values if they became available. This had the effect of both decoupling the main loop from each subsystem, and decoupling the subsystems from each other, since the main loop would not need to block while waiting for a value from either subsystem. This accommodated for very different output rates of each subsystem, and guaranteed that the main loop always had access to the most up-to-date values from either subsystem.",
                "This project is the biggest project I have seen through from start to finish, and I am very grateful to my team for putting in all the effort to make it a reality. It was incredibly rewarding to build a working prototype from nothing, based on an idea that we initially didn't even know was possible. I want to thank my team, Ridvan Song, Thomas Yoo, and Ben Pallottini for all their hard work and perspectives, and for being incredibly easy to work with despite this being a very stressful project for all of us."
            ],
            "imageID": 0
        },
        {
            "link": "http://silken.dev/calculator",
            "subheading": "A tool for visualizing the space of Pokemon EVs",
            "bodyParagraphs": [
                "When teambuilding for competitive Pokemon, it can be hard to tell how an EV investment translates into damage or survivability. This tool visualizes the space of possible damage so the user can optimize their EVs to squeeze the most out of their stats.",
                "This project was a lesson in iteration. I started with a pure js experiment, inputting the stats of the attacker and defender and the power of the move  and generating a graph of damage ranges for each EV point invested. The next step was to get the Pokemon data. I experimented with different data sources, starting with hitting PokeAPI endpoints to get species data and populating a list of all valid pokemon. This was a good start, but the shape of the data from PokeAPI was not convenient for what I needed, primarily because the names of pokemon were not consistent between the PokeAPI results and the results from the @smogon/calc package used for damage calculations. I then found the @pkmn/dex package, which has pokemon data that was designed to be compatible with the @smogon/calc.",
                "During each step of iteration, I let the shape of the data guide how I built the UI. As I iterated, I both learned more about the data I was working with as well as how I want user interactions to flow. Before my final iteration, I took a step back and mocked up the interface that I wanted to end with. Because I had learned the data shape so well, I felt confident in letting the interface lead my functionality.",
                "Following the last major iteration, I found myself writing a group of utility functions to modify the state of the selected pokemon. After realizing this, I knew that it would be a good idea to coalesce the state of the selected pokemon, along with these utility functions into a class - SelectedPokemon, but I felt a lot of inertia to make this change. Later in the project, I felt the same inertia when adding label tags to inputs for accessibility, doing it by hand instead of applying the pattern I had recognized and creating a component or wrapper for the input. ",
                "Reflecting on this feeling of inertia, for the rest of the project when I noticed this feeling of stubbornness in doing things the slow way, I took a step back and evaluated the way I was doing things and why I was doing them that way. If I couldn’t think of a reason why I was doing things the way I was, I would explore more in the opposite direction of the stubbornness I was feeling.",
                "While this continuous reflection and refactoring was good for getting code down quicker and not having to debug or optimize as much later, it was symptomatic of a decision I had made earlier. When I planned my final iteration, I chose to let the planned UI lead my development. This led to the UI dictating the way that the functionality code was written. This coupled the UI and functionality code much more tightly than they realistically should have been.",
                "Going forward, I want to work to decouple my interface and functionality code more explicitly. This could have been accomplished in this project by letting the shape of the data inform an explicit plan for the functionality, and then let the outputs of the planned functionality inform the plan for the UI. This way, the functionality comes first, and more time and effort can be spent refining the UI and user experience, instead of refactoring, debugging, and optimizing."
            ],
            "imageID": 3
        },
        {
            "link": "",
            "subheading": "A MERN app for playing a classic card game.",
            "bodyParagraphs": [
                "Crazy 8s was a project I took up with a friend of mine, Elin Liu, with the goals of practicing front and back-end development in Javascript. The project was inspired by online games such as Kahoot, where users don't need to create an account, they can just join a friend's game with a generated code.",
                "An important piece of functionality for us was real-time updates between the players in the game. This meant creating a websocket socket for each client, and grouping each connection to the server by the game room it joined. Then, on each player turn, the new state of the game could be  computed on the server and broadcast to each of the users in the game.",
                "In order to persist the game data, we used a mongoDB database and modelled each game as an object that we could pull from the database and broadcast to the players. This object would slowly be populated as a player created the game, players joined, the game was started and played, and finally as it finished.",
                "In hindsight, an SQL database would have been better suited for our needs in this project, as the client did not need the entire game object in order to render the changes that occurred on each turn.",
                "This project was a great experience, especially as it involved collaboration with another developer. We made progress on the project by working separately throughout the week and merging our changes on pair programming sessions on the weekend, after which we would decide what needed to be done and who would do it during the following week."
            ],
            "imageID": 1
        },
        {
            "link": "",
            "subheading": "A discord bot that makes fair teams for inhouse online games.",
            "bodyParagraphs": [
                "In mid-2021, a group of my friends found ourselves playing the videogame Valorant every night after school/work. A team in the standard mode is five players, but if a sixth friend joined, what would we do? The game has the option to make a custom lobby with smaller teams from the players in your party, so if a 6th person arrived, we would simply play 3v3.",
                "When playing the standard mode, we could rely on the game servers to find a balanced game for us to play in. But among ourselves, our skill levels varied wildly, and balancing teams felt arbitrary. That is the situation that inspired this project.",
                "This bot is written in python using the discord.py library to handle events. The bot had two main functions - to generate two teams from the players in the same call together, and track the winrate of each player after the game.",
                "The bot takes in commands by reading incoming messages sent in the servers it is connected to, and filtering out messages that don't contain command keywords. After making the teams, the bot sends a message to the server and waits for users to react to that message to indicate that either team1 won, team 2 won, or the match was cancelled.",
                "Once the match results are in, each player who participated has their win rates updated in a firebase firestore database. This database was set up to have a list of win-rates for each server, so that how you play with one group of friends doesn't necessarily correlate to how you play among another group.",
                "This project was satisfying and fun to work through, as it was very easy to mock up the endpoints for user interaction and database, and then spend more time focusing on the matchmaking to ensure a more balanced user experience."
            ],
            "imageID": null
        },
        {
            "link": "",
            "subheading": "An android app that determines a pokemon's hidden stats from a photo of its visible stats",
            "bodyParagraphs": [
                "In 2022, I found myself playing a lot of Pokemon Sword, specifically hunting for strong and rare shiny pokemon. I found this task frustrating, because while you could tell if a pokemon was shiny from a glance, to check if its hidden stats, or IVs, were good or perfect, you had to plug all the visible stats into an online calculator, which was a hassle.",
                "After going through this pattern one too many times, I had the idea to automate this process. The stats of the pokemon I caught were always located in the same location on the screen, and all the information I needed to put into the calculator was on the same screen. I needed to write an app.",
                "I wrote a basic front-end in react-native that could snap a photo of the screen, send it to a back-end server, and wait for a response. The back end had three components, an image processing component that compensated for the perspective warp of the game screen, a character recognition component that read the stats from the compensated image using OCR, and a re-implemented version of the online stat calculator that the stats could be read into.",
                "This project worked well for what it was, and I would be very interested to revisit it someday. I have a lot more experience with both machine learning and image processing techniques then I had when I threw this project together, and would love to create a more bespoke, performant, scalable solution using openCV, instead of relying on inefficient libraries that only partially solved the problems I had.",
                "I would also change the front-end experience. In the app's current form, it relies totally on a remote website, and as such doesn't necessarily need to be a native app to accomplish its purpose. Being a website, for example, would improve compatibility across platforms, and even allow users to upload screenshots directly from their games. Alternatively, implementing the machine learning and image processing tasks on native code sounds like a challenging, but rewarding upgrade to this project."
            ],
            "imageID": null
        }
    ]
}