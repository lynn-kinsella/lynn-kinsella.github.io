{
    "projectsMin": [
        {
            "name": "Mobile Mind",
            "desc": "An EEG and eye-tracking controlled wheelchair.",
            "id": 0
        },
        {
            "name": "Crazy 8s",
            "desc": "A React app for a classic card game.",
            "id": 1
        },
        {
            "name": "Match\u00ADmak\u00ADing Bot",
            "desc": "A discord bot to make fair games among friends.",
            "id": 2
        },
        {
            "name": "IV Calc\u00ADul\u00ADator",
            "desc": "An android app that determines a pokemon's hidden stats from a photo.",
            "id": 3
        }
    ],
    "projectsMax": [
        {
            "subheading": "A Hands Free EEG and Eye Tracking Controlled Electric Wheelchair",
            "bodyParagraphs": [
                "Mobile Mind is a hands free electric wheelchair, controlled using input from an EEG headband and eye tracking camera. The wheelchair responds to the user's intent to accelerate and decelerate based on their brainwaves, and turns to the left and right based on where they are looking. This project was completed over the course of 8 months in a team of 3 other students as our final year capstone project at McMaster University.",
                "In the early phase of the project, I worked with Ridvan Song to research and experiment with ways to transmit and process the EEG signals that our hardware acquired. Once we had established that we could send the signals over the internet via an Open Sound Control (OSC) server, I developed our first data acquisition experiments, where a user would be prompted to focus on the thought of either “STOP” or “GO”, and the signals from the EEG during that period would be saved and labelled for inspection, and later for training data. I then experimented with different data visualization techniques to evaluate the quality of our data, considering the possibility of using a spectrogram or discrete wavelet transform as both techniques account for changes in amplitude and frequency over time.",
                "In the later stages of the project, I wrote the back-end framework that accepted data from the input devices, processed that data in regular intervals, and sent output signals to the wheelchair motors. The EEG signals were transmitted via OSC like in the earlier experiments, and the video from the eye tracking camera was streamed over a TCPsocket. After being received, the signals were placed into shared queues so that they could be processed in the main process loop on the next iteration.",
                "The main loop was a state machine that took the raw signals, made predictions based on them (using a tensorflow model to predict the user's thought based on a buffer of samples or openCV to predict the direction the user is looking based on the placement of their irises). The results of these predictions were used to control internal speed and angle. Based on the predictions, in each iteration of the main loop the internal speed and angle were updated to step towards a target value. At the end of each loop, the internal speed and angle values were mapped to speeds for the left and right motors.",
                "The biggest challenge in my role with Mobile Mind was integrating all the subsystems together. I accomplished this by breaking each subsystem into its own process, both for modularity and performance. The main loop could request the most up to date values from each process via shared queues, and update its internal state with new values if they became available. This had the effect of both decoupling the main loop from each subsystem, and decoupling the subsystems from each other, since the main loop would not need to block while waiting for a value from either subsystem. This accommodated for very different output rates of each subsystem, and guaranteed that the main loop always had access to the most up-to-date values from either subsystem.",
                "This project is the biggest project I have seen through from start to finish, and I am very grateful to my team for putting in all the effort to make it a reality. It was incredibly rewarding to build a working prototype from nothing, based on an idea that we initially didn't even know was possible. I want to thank my team, Ridvan Song, Thomas Yoo, and Ben Pallottini for all their hard work and perspectives, and for being incredibly easy to work with despite this being a very stressful project for all of us."
            ],
            "imageID": 0
        },
        {
            "subheading": "A MERN app for playing a classic card game.",
            "bodyParagraphs": [
                "Crazy 8s was a project I took up with a friend of mine, Elin Liu, with the goals of practicing front and back-end development in Javascript. The project was inspired by online games such as Kahoot, where users don't need to create an account, they can just join a friend's game with a generated code.",
                "An important piece of functionality for us was real-time updates between the players in the game. This meant creating a websocket socket for each client, and grouping each connection to the server by the game room it joined. Then, on each player turn, the new state of the game could be  computed on the server and broadcast to each of the users in the game.",
                "In order to persist the game data, we used a mongoDB database and modelled each game as an object that we could pull from the database and broadcast to the players. This object would slowly be populated as a player created the game, players joined, the game was started and played, and finally as it finished.",
                "In hindsight, an SQL database would have been better suited for our needs in this project, as the client did not need the entire game object in order to render the changes that occurred on each turn.",
                "This project was a great experience, especially as it involved collaboration with another developer. We made progress on the project by working separately throughout the week and merging our changes on pair programming sessions on the weekend, after which we would decide what needed to be done and who would do it during the following week."
            ],
            "imageID": 1
        },
        {
            "subheading": "A discord bot that makes fair teams for inhouse online games.",
            "bodyParagraphs": [
                "In mid-2021, a group of my friends found ourselves playing the videogame Valorant every night after school/work. A team in the standard mode is five players, but if a sixth friend joined, what would we do? The game has the option to make a custom lobby with smaller teams from the players in your party, so if a 6th person arrived, we would simply play 3v3.",
                "When playing the standard mode, we could rely on the game servers to find a balanced game for us to play in. But among ourselves, our skill levels varied wildly, and balancing teams felt arbitrary. That is the situation that inspired this project.",
                "This bot is written in python using the discord.py library to handle events. The bot had two main functions - to generate two teams from the players in the same call together, and track the winrate of each player after the game.",
                "The bot takes in commands by reading incoming messages sent in the servers it is connected to, and filtering out messages that don't contain command keywords. After making the teams, the bot sends a message to the server and waits for users to react to that message to indicate that either team1 won, team 2 won, or the match was cancelled.",
                "Once the match results are in, each player who participated has their win rates updated in a firebase firestore database. This database was set up to have a list of win-rates for each server, so that how you play with one group of friends doesn't necessarily correlate to how you play among another group.",
                "This project was satisfying and fun to work through, as it was very easy to mock up the endpoints for user interaction and database, and then spend more time focusing on the matchmaking to ensure a more balanced user experience."
            ],
            "imageID": null
        },
        {
            "subheading": "An android app that determines a pokemon's hidden stats from a photo of its visible stats",
            "bodyParagraphs": [
                "In 2022, I found myself playing a lot of Pokemon Sword, specifically hunting for strong and rare shiny pokemon. I found this task frustrating, because while you could tell if a pokemon was shiny from a glance, to check if its hidden stats, or IVs, were good or perfect, you had to plug all the visible stats into an online calculator, which was a hassle.",
                "After going through this pattern one too many times, I had the idea to automate this process. The stats of the pokemon I caught were always located in the same location on the screen, and all the information I needed to put into the calculator was on the same screen. I needed to write an app.",
                "I wrote a basic front-end in react-native that could snap a photo of the screen, send it to a back-end server, and wait for a response. The back end had three components, an image processing component that compensated for the perspective warp of the game screen, a character recognition component that read the stats from the compensated image using OCR, and a re-implemented version of the online stat calculator that the stats could be read into.",
                "This project worked well for what it was, and I would be very interested to revisit it someday. I have a lot more experience with both machine learning and image processing techniques then I had when I threw this project together, and would love to create a more bespoke, performant, scalable solution using openCV, instead of relying on inefficient libraries that only partially solved the problems I had.",
                "I would also change the front-end experience. In the app's current form, it relies totally on a remote website, and as such doesn't necessarily need to be a native app to accomplish its purpose. Being a website, for example, would improve compatibility across platforms, and even allow users to upload screenshots directly from their games. Alternatively, implementing the machine learning and image processing tasks on native code sounds like a challenging, but rewarding upgrade to this project."
            ],
            "imageID": null
        }
    ]
}